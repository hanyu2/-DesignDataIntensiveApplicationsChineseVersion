# 第一部分

# 数据系统基础

前四章将会浏览一遍应用在所有数据系统上的基本思想，不论是单节点还是分布式机器：

1. 第一章介绍贯穿本书中使用的术语和方法。我们将会认真定义我们使用的一些用辞，比如可靠性，可扩展性，可维护性，我们也会探讨我们是如何尝试完成这些目标的。
2. 在第二章，我们将会比较几种不通的数据模型和查询语言——这是程序员眼中不同数据库之间最大的差异。我们也会了解各种模型是如何适应不同的场景的
3. 在第三章我们会回到存储引擎的内部来看一下数据库如何在磁盘上组织数据。不通的存储引擎针对不同的工作量有各自的优化，选择正确的优化策略会对性能有着极大的影响。
4. 在第四章我们会对比不同的数据编码（序列化）格式，尤其会着重关注在应用的需求改变和schema随着时间演变的过程中编码格式是如何表现的。

此后在第二部分我们会转向讨论分布式数据系统的具体问题。

![](https://vonng.gitbooks.io/ddia-cn/content/img/ch1.png)

# 第一章

# 可靠的，可扩展的，可维护的应用

> 互联网做得如此出色以至于很多人觉得他们像太平洋一样的自然资源，而不是像是一个人工产物。上一次出现如此大规模且无差错的技术是什么时候？
>
> ——阿兰·凯在接受Dobb博士杂志采访时说（2012年）

当代的很多应用都是数据密集型的，而不是计算密集型。CPU的算力已经不是这些应用的限制因素，更大的问题是数据的量级，数据的复杂度和数据的演变速度。

一个数据密集型的应用一般来说是由服务常用功能的标准模块集成起来的。比如，很多应用需要：

- 存储数据以供自己或者其他以应用读取（数据库）
- 缓存复杂运算的结果来加速读取（缓存）
- 允许用户通过关键词或者各种过滤搜索（搜索索引）
- 发送消息给其他进程去实现异步处理（流处理）
- 定期处理积累的大批量数据（批处理）

如果那听起来过于太平平无奇，是因为数据系统抽象的太完美：我们总在用他们却缺乏思考。在开发一个应用时，大部分的工程师并不会幻想从0写一个新的数据数据存储引擎，因为数据可时做这件事的完美工具。

但事实并非如此简单。很多数据库有不同的特性，因为不同的应用有不同的要求。有很多不同的方法做缓存，搜索索引等等。在开发一个应用时，我们任然需要找出哪一种工具，哪一种方法是最适合我们手头的任务需求。当一件供给无法独立完成一项需求的时候，综合使用多种工具同样可能会很有难度。

这本书是一本穿越数据系统的原理，实践的旅程，也会讲解我们是如何用他们开发数据密集的应用。我们会探索不同工具的共同点，各自的特点和他们是如何实现的自己的特性的。

在这一章，我们会通过探索我我们基础目标：可靠性，扩展性，可维护性的数据系统开始。我们会弄清这些词是什么意思，概括思考他们的方法，并了解后续章节的一些基本知识。在后续章节中我们会继续分层查看各种数据密集型应用的开发中需要考虑的各种不同设计决策。

## 关于数据系统的思考

我们习惯性的以为数据库，队列，缓存等等是非常不同的工具类别。尽管数据库和消息队列有着非常明显的共性——他们都会把数据存一段时间——但是他们有着非常不同的读取模式，那就意味着有不同的性能特性，也会有非常不同的实现方法。

所以我们为什么把他们混在数据系统这个大伞之下呢？

近些年有很多新生的数据存储和处理的工具。他们针对各种不同的使用场景做了优化，他们也不完美地归纳到传统类别。比如，数据存储也被用作消息队列（Redis）,同样也有消息队列有着数据库特性的持久性保证（Apache Kafka）。这些类别之间的界限正在面的越来越模糊。

第二，有越来越多的应用现在有着单一工具对其数据处理和数据存储无法满足的强烈广泛的需求。取而代之的是这些工作被拆解成了单一工具可以高效工作的任务，这些不同的工具不应用程序的代码串联起来。

比如，如果你有一个应用层面馆里的缓存层（使用Memcached或类似的），或者一个有一个和主数据库分离的全文检索服务器（例如Elasticsearch或者Solar），很自然的是应用程序的代码需要负责缓存和索引系统与主数据库的同步。图1-1给出了这个系统的大致轮廓（我们会在后续章节深入探究）。

![](https://vonng.gitbooks.io/ddia-cn/content/img/fig1-1.png)

*图1-1 一个集成多各组件的数据系统的可能架构*

当你为了服务用户来集成一些工具是，服务的接口或者服务的API的实现通常是对于客户端是不可见的。现在你已经使用较小的，有通用功能的组件开发了一个新的，有特定目的的数据系统。你的复合的数据系统可能能提供一些保证：比如，缓存可以在写入的时候可以正确地作废或者更新以保证客户端可以看到一致的结果。你现在不仅只是一个应用的开发者，也是一个数据系统的设计者。

如果你正在设计一个数据系统或者服务，会遇到很多棘手的问题。党内部系统出错时，你如何保证数据的正确性和完整性？当部分系统降级服务，如何保证对客户端稳定的高性能服务？负载增加时如何扩容？一个好的服务API应该是什么样的。

有你多因素影响着你的数据系统的设计，包括参与人员的技术和经验，历史遗留系统的依赖，交付时间，你的公司对不同风险的承受能力，和法规限制，这些因素都要具体情况具体分析。

在这本书里，我们关注在一下三个对大多数软件系统都至关重要的方面：

*可靠性*

系统应该持续正常工作（功能在期望的性能下运行）即便遇到问题（硬件或者软件缺陷，甚至是人为错误）。

*可扩展性*

当系统在增长时（数据量，流量，或者复杂度），应该有合理的办法应对这种增长

*可维护性*

在一段时间内，很多不同的人在一个系统上开发（工程师，运维都会维护当前系统的正常运行并适应新的应用场景），他们都应该能高效地在这个系统中工作。

人们经常会去努力完成以上的目标却没有一个准确清晰的定义。为了做到有思想的工程，我们会在本章剩余的内容中探索可靠性，可扩展性，可维护性的思考方式。然后在此后的章节里我们会探寻为了达成这些目标的各种技巧，架构和算法。

## 可靠性

每个人都有对于可靠或者不可靠的理解。对于软件来说，通常的期望包括：

- 应用的运行符合用户期望
- 对于用户的使用错误或者非常规的使用方法有容错能力
- 在预期的负载和数据量下对于要求的使用场景下性能表现依然良好
- 系统可以组织任何未经授权的访问和滥用

如果所有的这些放在一起代表着“工作正常”，那么我们粗略地把*可靠性*理解为“即使出现问题也能正常工作”

出错的地方我们叫做*故障*，能够遇见故障并能解决他们的被称作*容错的*或者是*有韧性*的系统。前一个词可能会有误导：它意味着我们可以开发一个能容纳各种可能故障的系统，现实里其实是不可能做到的。如果整个地球（包括地球上的所有服务器）都被一个黑洞吞噬，如果需要包容这种错误需要把web服务器放在太空，如果申请这种预算那只能祝你好运了。所以讨论特定类型的容错才有意义。

注意故障不等同于失效。故障通常被定义为系统中的一个组件偏离其标准，但是*失效*是整个系统停止了对用户承诺的服务。我们无法把故障率降低到0，因此设计容错机制通常最好的设计是防止故障导致的失效。本书中我们会介绍几种从不可靠的组件中开发可靠系统的技术。

反直觉的是，在这种容错系统中，有意地触发付账来导致故障率的上升是有意义的，例如在没有警报地情况下随机杀掉一个进程。很多致命的bug是由于差强人意的错误处理导致的；通过有意地引入这些故障能保证容错机制持续运行并接受考验，这样能才能增强处理自然出现的bug被正确处理的信心。Netflix公司的*Chaos Monkey*就是这种方式的例子。

虽然我们通常倾向于容错而不是预防故障，但有些情况预防比处理更高（比如没有处理方法）。有一种情况是关键的安全问题，比如说：如果一个攻击者破坏了系统并拿到了敏感数据的读取权限，这种情况甚至不能撤销。但是这本书主要处理的是能够被处理的故障，就像下面这节描述的一样。

## 硬件故障

当我们思考系统失效原因的时候，硬件故障会迅速闪现在脑海中。硬盘崩溃，RAM错误，电网断电，有人拔错了网线。又在大型数据中心工作经验的人会告诉你如果你有很多机器这些情况经常发生。

据报道称，硬盘的平均无故障时间（MTTF），是大约10到50年。因此，在一个有10,000个硬盘的存储集群中，我们是认为每天有一块硬盘故障是正常的。

我们首要的应对方法通常是对单一硬件组件增加冗余去降低系统的失效率。硬盘可能是组织在RAID磁盘阵列上，服务器可能是有双电源系统和热插拔CPU，数据中心可能有电池系统或者柴油发电机作为备用电源。当一个组件当及时，冗余组件可以代替失效组件，这种方法没法完全避免硬件问题带来的失效，但是是大家公认的可以让一台机器无中断运行很多年的方法。

甚至直到最近，冗余的硬件组件依然可能足够支持大多数应用，因为单机的完全失效已变得十分罕见。只要你可以在快速地把备份恢复到一台新机器，这种失效带导致的停机时间在大多数应用中都不是灾难性的。因此多机冗余只对少数要求高可用的应用才是十分必要的。

但是，数据量和应用的计算需求已经大幅增加，很多应用已经开始大量使用机器，这样会相应地增加硬件故障率。除此之外，在一些例如AWS的云平台上，虚拟机实例再无任何警报的情况下不可用也是相当常见的，因为这个云平台设计的的灵活性（flexibility）和弹性（elasticity）的优先级高于单机可靠性的优先级。

如果在硬件冗余的基础上进一步使用软件容错机制，因此在容忍全部机器失效的路上就更进一步。这样的系统也有运维上的便利：重启单节点的服务器系统（比如安装系统安全补丁）需要有计划的停机时间，但是允许机器失效的系统可以一次只给一台机器打补丁而不会造成整个系统的停机。

## 软件错误

我们通常认为硬件故障是很随机的，相互独立的：一台机器的硬盘失效并不意味着另外一台机器的硬盘也会失效。但是有可能会有弱关联（比如因为一些常见原因，像是家家温度），否则不大可能大量的硬件组件会同时失效。

另外一种故障类型是系统性故障。这种故障难以预见，因为他们在节点之间是相互关联的，所以比起不相关的硬件故障他们会导致更多系统性失效。比如：

- 一种非法输入引发的软件bug造成应用客户端的每一个实例崩溃。比如2012年6月30日的闰秒，由于Linux内核bug造成了许多应用同时挂掉。
- 失控进程会耗光一些共享资源——CPU时间，内存，磁盘空间或者网络带宽。
- 程序依赖的一个服务变慢，变成无响应或者返回错误应答。
- 级联故障，一个组件里的小故障会出发另一个组件故障，从而引发自己更多的故障。

造成这些软件故障的bug通常会潜伏很长时间才被一些异常的情况触发。这些情况意味着软件会对它的环境做一些假设——虽然那种假设通常是正确的，但是在某些情况下却不再成立。

软件中的这种系统性故障并没有一种快速的解决办法。有很多办法会有帮助：仔细考虑系统中的假设和交互；彻底的测试；进程隔离；允许进程崩溃重启；测量，监控和分析线上系统的系统行为。如果一个系统能够提供一些保证（比如消息队列中的进入消息与发出消息数量相等），系统会在运行的时候持续检查并在出现差异时发出报警。

## 人为错误

设计开发和维护软件系统运行的都是人类。即便人类有最大的善心，但人类同样被认为是不可靠的。比如，一个关于大型互联网服务的研究表明，运维人员的配置错误是导致读点的主要原因，然而硬件故障（服务或者网络）之只占断电的10%-25%。

尽管人类并不可靠，我们如何让我们的系统更可靠？最好的系统结合了几个方法：

- 用能最小化错误的方法设计系统。比如，设计良好的抽象，API和管理员界面可以让我们做“正确的事”更容易，做“错误的事”更难。但是如果界面给人的限制太多，人们会找方法绕过他们，这样就丢掉了界面带来的好处，所以想做到正确也有一种微妙的平衡。
- 把人们容易犯错的地方和容易造成失效的地方解耦。尤其是提供一个功能齐全的非生产*沙箱*环境，所以开发人员可以在不影响真实用户的情况下安全的用真实数据探索和试验。
- 在各个层次做彻底的测试，同单元测试到全系统集成测试，到人工测试。自动化测试被广泛使用和了解，对cover正常运行中罕见发生的边缘情况尤为重要。
- 允许从人为错误中迅速简单地恢复来最小化失效带来的影响。比如，可以加速回滚配置的更改，分批上线代码（所以任何未预料的bug只影响一小部分的用户），提供重新计算数据的工具（预防旧的数据计算错误）。
- 配置详尽清晰地报警，比如性能指标和故障率。在其他工程学科中这通常叫做*遥测*。（一旦火箭离开了地面，遥测对于监控正在发生的情况是至关重要的）。监控可以给我们早期的报警信号，帮助我们检查任何地方违反了假设或限制。当一个问题出现时，指标对诊断问题是很有用的。
- 贯彻良好的管理实践和培训——这是一个复杂且重要的方向，不再本书的讨论范围内。

## 可靠性有多重要？

可靠性不是指针对核电站和航空流量管制软件——更多普通的软件也需要可靠地运行。商业软件中的bug会造成生产力降低（如果数据错误还会有法务风险），电商网站的终端也会造成收入和声誉的巨大损失。

甚至在“不重要”的应用中我们也需要对我们的用户负责人。想一下分木门把他们孩子的所有照片和视频粗在了你的相片应用中。如果你的数据库突然挂了他们感受是什么样的。他们会从备份中恢复吗？

有些情况下我们会选择牺牲可靠性来降低开发成本（比如在对未经验证的市场开发产品原型的时候）或者运营成本（比如利润极低的服务）——但我们偷工减料时我们应该非常清醒地意识到这些问题。

## 可扩展性

即使一个系统在今天很可靠地在运行，那也不意味着以后也能可靠地运行。一个常见的服务降级的原因是增加的负载：有可能是系统从10,000个并发用户增长到100,000，或者是从一百万涨到一千万。有可能系统处理了比以前大得多的数据。

可扩展性是我们用来描述系统处理增长的负载的能力的术语。但是要注意，他不是我们赋予一个系统的一个一维标签：说“X是可扩展的”或者“Y是不可扩展的”是没有意义的。而是，当我们讨论可扩展性是意味着要思考这种问题“如果系统以某种方式增长，我们应对这种增长有什么选择？”和“我们如何增加计算资源来处理这种额外的负载”。

## 描述负载

首先，我们需要简洁地描述系统当前的负载；然后我们才能讨论增长问题（如果我们的负载翻倍怎么办？）。我们可以用几个叫做*负载参数*的数字描述符在。选择参数的最好方法跟系统的架构有关：对于网络服务器可能是每秒请求数，对于数据库是读写比，对于聊天室是同时在线人数，对于缓存是命中率等。可能平均情况对你很重要，也可能一些少量的极端情况是你的瓶颈的主要因素。

让我们用Twitter 2012年11月发布的数据的例子来让这个概念更加具体。Twitter两种主要的业务是：

*发推特*

用户可以给他们的粉丝发新消息（平均每秒4.5k请求，峰值每秒超过12k）。

*主页时间线*

用户可以看他们关注的人发的推特（每秒300k）。

每秒处理12k的写入（发推的峰值）还是很简单的。但是Twitter的扩展性挑战并不单纯由于推特量，而是扇出（fan-out）,每个人会关注很多用户，每个用户又会被很多人关注。大致上有两种方法来实现这两种业务：

1. 发一条推个只是往全局所有的推特里插入一条新的推特。当用户请求主页时间线的时候，查询这个用户关注的所有人，找出每个关注的人发的所有推特，然后把他们合并到一起（按时间排序），在一个关系型数据库中就像图1-2，query就像：

```sql
SELECT tweets.*, users.* FROM tweets
JOIN users ON tweets.sender_id = users.id
JOIN follows ON follows.followee_id = users.id
WHERE follows.follower_id = current_user
```

![](https://vonng.gitbooks.io/ddia-cn/content/img/fig1-2.png)

*图1-2 Twitter首页时间线的简单关系型模式的实现*

2. 给每个用户的首页时间线维护一个缓存——就像给每个粉丝有一个推特的收件箱（图1-3）。当一个用户发推时，找出他所有的粉丝，并给每个粉丝的首页时间线缓存里插入这条推文。所以在请求读首页时间线时开销很小，因为这个结果是已经提前计算好的。

![](https://vonng.gitbooks.io/ddia-cn/content/img/fig1-3.png)

*图1-3 Twitter的推送给粉丝的数据流水线，负载情况基于2012年12月的情况*

第一版的推特用了第一种方法，但是系统在首页时间线访问量增大时显得捉襟见肘，所以Twitter切换到了第二种方法。这种方法表现更加因为平均发推率比首页时间线读取率几乎低两个量级，所这种情况下在写得时候会多做一下工作，但是读的时候少做一些工作。

但是第二种方法的弊端是，发推特需要很多额外的工作。在平均情况下，一条推文会推送给75个粉丝，所以每秒4.6k条推文对首页时间线缓存变成了每秒345k写入，但是这种平均情况掩盖了每个人粉丝数量差异巨大的事实，有些用户有超过三千万的粉丝。这样就意味着单条退分可能导致要在首页时间线有三千万条写入！推特尝试在5秒内把推文推送给粉丝，但要及时完成这项工作是一个巨大的挑战。

在推特的例子里，永福粉丝数量的分布（也可能加权用户的发推频率）对讨论可扩展性是一个关键的负载指标，因为它决定了扇出负载。你的应用可能有着截然不同的特性，但是你可以通过使用类似的原理来分析其负载。

Twitter反转的轶事：现在已经稳健地实现了第二个方法。Twitter正在想着一种结合了两种方法的混合模式进步。大部分用户的发推文还是会被扇出到时间线，但是对少量粉丝量巨大的用户不适用这种扇出方法。粉丝关注的名人的推文会被另外读取，并在用户读首页时间线时合并进去，就像第一种方法。这种混合模式能够持续提供高性能。我们会在第十二章学习完更多的技术内幕之后重新审视这个例子。

## 描述性能

当你描述完你的系统负载以后，你就可以来调查负载增大时发生的是。你可以从以下两种方式来做：

- 当你增大了负载参数并保持系统资源（CPU，内存，网络带宽等）不变，你的系统性能会受到怎样的影响？
- 当你增大了负载参数，并想保持性能不变你需要增加多少资源？

这两个问题都需要性能指标，所以让我们简要地看一下描述系统性能的方式。

在例如Hadoop的批处理的系统中，我们通常关心*吞吐量*——每秒可以处理的数据数量，或者是在一个特定大小的数据及上跑一个job的总时间。在在线系统中，通常更重要的是系统*响应时间*——也就是客户端发出一个请求并得到相应中间所花的时间。

> ### 延迟和响应时间
>
> 延迟和响应时间经常用作同义词，但是他们并不是完全相同的。响应时间是客户端看到的：除了实际处理请求的时间（服务时间），他还包括网络延时和排队延迟。延迟是请求等待处理的时间——在这个时间内他是休眠的，等待服务的。

即使你只是一遍一遍发送相同的请求，每次得到的响应时间也是有细微不同的。在实际工作中。一个处理各种各样请求的系统的反应时间偏差是会很大的。因此我们需要把响应时间只看做一个单独的数字，而是你测量范围内的分布情况。

在图1-4中，每个灰色的条都是一个向服务发起的请求，高度是请求话费的时间。大部分请求都是很快的，但是有花费了很长时间的极端情况。有可能这些慢的请求本身就是十分好非自愿的，比如他们处理了更多数据。但是在你觉得所有的请求都应该花一样的时间的场景中，同样也有变化：上下文切换到后台进程可能带来随机的额外延迟，丢包和TCP重传，垃圾回收等待，分页错误导致的磁盘重读，服务器机架的机械振动，或其他很多原因。

![](https://vonng.gitbooks.io/ddia-cn/content/img/fig1-4.png)

*图 1-4. 展示了服务了100个请求取样的平均值和百分位值*

通常服务报表都会显示*平均*响应时间（严格来说，*平均*没有用任何公示，在实际中就是通常理解的*算术*平均值：给你n个数，把他们加起来求和再除以n）。但是，你想知道你系统“典型的”响应时间，平均值并不是一个很好的指标，因为他没告诉你有多少用户遭到了延迟。

通常用*百分位数*封号。如果你拿到一串响应时间按从快到慢排序，*中位数*是半程的那个点：比如，如果你的响应时间中位数是200毫秒，那意味着你有一般响应的时间小于200毫秒，一半大于200毫秒。

如果你想知道用户通常花了多少时间等待，这样看起来中位数是一个不错的指标：有一半的用户响应时间小于中位数，另一半大于。中位数也被乘称作50百分位点，有时缩写为*p50*。请注意中位数代指一个请求，如果一个用户发出了许多请求（在一个会话中，或者因为一个也变包含许多资源），那样这些请求中至少一个请求比中位数慢的可能性远远大于50%。

为了找出极端情况的糟糕程度，可以通过看更高的百分位点：通常看95，99和99.9百分位点（缩写为*p95*，*p99*，*p999*）。这几个是响应时间的阈值，有95%，99%，99.9%的请求都比这个阈值快。比如：如果95百分位点的响应时间是1.5秒，那意味着100个请求里面有95个请求用的时间比1.5秒少，有5个用了大于等于1.5秒。图1-4也有展示。

响应时间的高分位点也被称为*尾部延迟*，这些是很重要的应为他们直接影响着服务带给用户的体验。比如，即便在1000个请求中只影响一个，亚马逊还是用99.9分位点描述内部服务的相应时间的要求。这是因为常常是用户账户数据量最大的用户请求最慢，因为他们买了很多东西——这也是最值钱的客户。通过保证网站对他们反应很快对保持这些用户愉快购物时很重要的：亚马逊同样观察到，反应时间慢100毫秒销售额会降低1%，另外的报道称一秒的延迟会导致用户满意率降低16%。

在另一方面，优化99.99分位点（10,000个里最慢的一个）被认为太昂贵了，不能为亚马逊带了足够的好处。降低高分位点的响应时间太困难了，因为他们经常受到控制外的随机时间影响，带来的收益也烟消云散了。

比如，*服务级别目标*（SLO）和*服务级别协议*（SLA）经常用到分位点，这是用来定义预期性能和服务可用性的合同。一个SLA的中位数相应时间少于200毫秒并且99分位点少于1秒（如果响应时间更长也会被认为是不可用的），SLA就可以宣称服务是可用的，系统也可能被要求99.9%的时间是可用的。这些指标给服务客户设置了预期，如果SLA没有达成允许客户退款。

排队延迟通常是大多数高分位响应时间的始作俑者。当服务器只能并行（有限制，比如CPU核书）处理少量事情时，少量的请求就能延迟后续的请求——这种现象有事被称作*头部阻塞*。即使这台服务器能很快处理后续请求，由于客户端一直在等之前的请求完成，客户端看到的是一个总体缓慢的响应时间。由于这种现象，观测客户端的响应时间也是很重要的。

当人为产生大量负载来测试系统的可扩展性时，负载产生端需要独立于响应时间一直发送请求。如果生产端等待前一个请求完成再发下一个，这样的话会造成在测试中人为把排队时间缩短，而不是现实情况，这样会造成测试结果偏差。

> 百分位点实践
>
> 在多重调用的后端服务里，高百分位点变得异常重要。即使你并行调用，终端用户的请求仍需要等待并行调用中最慢的那一个完成。一个慢的调用就会导致用户整个请求变慢，像图1-5中的那样。即使有很少量的后端调用很慢，如果一个用户的请求需要多重吊桶，遇到慢的调用几率会增大，用户遇到慢请求的比例也会升高（一种被称为*尾部延迟放大*的现象）。
>
> 如果你想给你的服务监控面板增加一个响应时间百分位，你需要持续有效地计算他们。比如你想维护一个过去10分钟响应时间的滑动窗口个。每分钟你要根据窗口计算中位数和各种分位数，然后把这些指标画在图上。
>
> 一种简单的实现是维护一个滑动时间窗口内所有请求的响应时间的列表，每分钟排序这个列表。如果你觉得这个不够有效，有一种算法可以在最低CPU和内存消耗上计算出一个很好的百分位预估值，这种算法有向前衰减，t-digest，或者HdrHistogram。请注意计算平均百分位数，比如减少时间频度或者从多台机器合并数值在算术上是没有意义的——正确的聚合响应时间数据的方法是添加直方图。
>
> ![](https://vonng.gitbooks.io/ddia-cn/content/img/fig1-5.png)
>
> *图1-5 当一个请求需要很多后端调用时，一个慢的请求就能拖慢整个用户请求。*

## 应对负载的方法

现在我们已经讨论了描述负载和性能指标的参数，我们可以认真开始讨论课扩展性了：当我们的负载参数增加一定程度时我们如何维持良好的性能呢？

适应某个级别负载的架构不太可能应付10倍于此的负载。如果你在开发一个一个增长特别快的服务，你用该在每次负载量级增加的时候重新考虑你的加过，或者更频繁地考虑。

人们经常讨论*纵向扩展*（垂直扩展，转向更强大的机器）和*横向扩展*（水平扩展，把负载分散在很多小的机器上）。在多机上分散负载也被称作是一种*无共享*架构。一个可以再单机上运行的系统一般简单很多，但是高性能的机器会是非常昂贵的，所以集中负载经常无法避免横向扩展。事实上，一个好的架构通常需要一种两种方法务实地结合：比如，用几个高性能机器比用很多小的虚拟机更简单，廉价。

有一些系统是有*弹性*的，，哪一位着他们在探测到负载增加是可以自动增加计算资源，但是其他系统需要人工调整（需要人来分析并决定给系统增加更多机器）。一颗有弹性的系统在负载数极为不可预测的情况下是很有用的，但是人工调整的系统是更简单，意外操作也会更少（参考重新平衡分区）。

把无状态服务部署在很多机器上是很直观的，把有状态的数据系统从单一节点配置成分布式的可能会带来额外的复杂度。因此，一种最近的通识是，到你的系统逼迫你不得不去改造成分布式去满足扩容或者高可用之前，一直用单一节点的数据库。

当分布式系统的工具和抽象变的越来越好，这种同事可能会变，至少对一些类型的应用是这样的。我们可以构想分布式数据系统以后会成为业界标杆，不管是不是需要处理大量的数据或者流量。在本书剩下的内容里，我们会学习一些分布式数据系统类型，讨论他们是如何在满足可扩展性的基础上做到易用和可维护的。

运行在大规模集群上的系统架构通常是针对一种应用类型——没有一种普遍的，能适用所有的可扩展架构（不正式的叫法：**万金油（magic scaling sauce）**）。应用的额问题可能是读取量，写入量，数据存数量，数据复杂度，响应时间要求，访问模式或者（通常是）所有这些再结合更多的问题。

比如一个设计处理每秒100,000个请求的系统，每个是1KB，会看起来与另外一个设计每分钟3个请求，每个2GB大小的系统的截然不同的，尽管这两种系统都有相同的吞吐量。

一个能对一种应用扩容应对自如的架构是在基于一些假设上构建的——哪些操作是常见的，哪些是罕见的——这也就是所谓的负载参数。如果这些假设事后看是错的，所有的为了扩展所以的努力都是白费的，最糟糕甚至可能有反作用。在早期的创业公司或者未证明产品的中，通常更重要的是产品功能的迅速迭代而不是假想的飞来负载。

即使这些都是只针对特定应用，可扩展架构也是通常又一些通用的模块用一种常见的模式构建成的。在这本书里我们会讨论这些模块和模式。

## 可维护性

众所周知的是软件的主要成本并不在早期开发，可是在持续的维护中——修bug，保证系统运转，调查失效，适应新平台，为了新场景改造，偿还技术债，添加新功能。

但是，不幸的是，很酷哦开发软件系统的不喜欢维护所谓的*遗留*系统——有可能包括修改别人的错误，在过时的平台上开发，或者系统被迫要做不属于自己的事。每个遗留系统都以自己的方式让人不爽，所以很难给一个通用的建议来和他们打交道。

但是我们可以用最小化维护代价的方法来设计系统，因此可以避免我们自己开发一个遗留的软件。为此，我们会特别注意软件系统的三种设计准则：

*可操作性*

方便运维团队保证系统平稳运行。

*简单性*

通过尽量删除系统中的复杂度来方便新程序员理解系统。（注意这不同于用户界面的简单性）。

*可进化性*

方便程序员在未来更容易修改系统和适应未预见的适应场景。通常也被称为可扩展性（extensibility）**，**可修改性（modifiability）或可塑性（plasticity）。

和前文说的可靠性和可扩展性一样，同样没有简单的方法来达成这些目标。更甚的是，我们还要考虑系统的可操作性性，简单性和可进化型

## 可操作性：让操作更加简单

有人说“好操作经常能让工作绕过糟糕（或者不完整）软件的限制，但是糟糕的操作可能让好软件运行不可靠”。尽管有些操作可以也应该被自动化，但是那仍然需要人类来首先配置自动化来让其正常工作。

运维团队对保证软件系统正常运行至关重要。一个好的运维团队通常对以下或者更多的工作负责：

- 监控系统健康情况，在陷入错误状态时能迅速恢复系统
- 跟踪问题原因，比如系统失效或者性能变差
- 及时更新软件和平台，比如安全补丁
- 了解系统之间的相互作用，所以才能在造成问题前预防问题
- 预测未来问题，在他们发生之前解决（比如容量规划）
- 给部署，配置管理等建立好的操作实践和开发工具
- 执行复杂的运维计划，比如从一个平台迁移到另外一个平台
- 配置更改时维护系统安全性
- 定义工作流程，让运维操作可预测，并保证身缠系统稳定
- 即使有人加入，有人离职，也能保证组内保留系统的相关知识

好的操作意味着日常工作更简单，解放运维团队的时间去做更重要的事。数据系统可以做很多事来保持日常工作的简单性，包括：

- 用好的监控来观测运行状态和内部系统
- 给自动化和接入标准工具提供良好帮助
- 避免依赖单台机器（容忍机器被下线去做维护但是整个系统还是无重断运行）。
- 提供良好的文档和易于理解的操作模型（“如果我做了X，会导致Y”）
- 提供良好的默认行为，同样有必要时给管理员权限去修改默认行为
- 适当的地方可以自愈，但是有必要时允许管理员人工干预系统状态
- 保证可预见的行为，最小化意外行为

## 简单性：管理复杂度

小的软件系统可能有令人愉悦的简单性和很短小强大的代码，但是当项目变得越来越大的时候，他们常常会变得非常复杂并难以理解。这种复杂度扩满了每个开发人员的工作效率，未来也会增加维护成本。一个深陷复杂度困境的软件项目通常也被称为*一坨烂泥*。

复杂度有很多可能的症状：状态空间爆炸，紧密耦合的模块，错中复杂的依赖，乱七八糟的命名方式和术语，为了节约性能问题的奇技淫巧，为了解决其他地方问些去做特定的逃逸，还有更多更多。

当复杂度导致运维困难的时候，预算和时间安排通常会超支。在复杂的软件中，修改代码导致的bug有更大的危险性。当一个系统让开发者难以理解的时候，隐藏的假设，未预计的结果，和未预测的交互更容易被忽视。相反，降低复杂东可能大幅度提升软件的可维护性，因此简单性使我们所开发系统的一个重要指标。

把一个系统做到更简单并不意味着阉割了他的功能，那同样代表着我们移除了*意外的*复杂度。Moseley和Marks把意外的复杂度定义为：是从实现中显现出来，而不是软件本身想解决的问题。

一个避免意外复杂度的好办法是*抽象*。一个好的抽象可能把很多的实现细节抽象得非常简练，让人很容易理解。好的抽象也可以被用到各种各样的应用上。这种服用不仅比重复造轮子更有效，同样质量也更高，抽象组件的质量提升也会对用到它的所有应用带来好处。

比如，高级编程语言是机器代码，CPU寄存器和系统调用的抽象。SQL一是一种抽象，隐藏了复杂磁盘和内存数据结构，来自其他客户端的并发，和宕机抽造成的不一致性。因此，在写高级编程语言的时候，我们仍在使用机器码，我们只是没有*直接*使用它，因为编程语言的抽象帮我们省略了机器码的实现细节。

但是找到一种好的抽象是很困难的。在分布式系统的领域中，属于然有很多好的算法，但我我们如何打包抽象来维护我们的系统福再度在一个可管理的水平长仍旧是不清楚的。

通过这本书，我们会注意好的抽象是如何帮我们维护系统的部分组件来建造一个经过清楚定义，可复用的组件。

## 可进化性：让修改更简单

你的系统的需求永远保持不变是几乎不可能的。更有可能是一种常态的变化中：之前没计划的使用场景出现，业务由县级的改变，用户对新功能的需求，新平台替代旧平台，法务或者监管需求改变，系统增长导致架构改变等。

在组织的流程来说，*敏捷*工作模式为适应改变提供了一种框架。敏捷社区同样开发出了技术工具和模式来帮我我们在一个经常改变的环境中开发软件，比如测试驱动开发（TDD）和重构。

对敏捷技术的大部分讨论都关注在一些很小的归你（同一个应用中的几个源代码文件）。在这本书中，我们会研究几种在更大规模的数据系统中提高敏捷性的方法，这些系统有可能包括几种不同的应用，或者集中有不同特性的服务。比如，你如何为了组织首页时间线来“重构”Twitter的架构从前文讨论的方法一到方法二。

你越容易修改一个数据系统并适应新的要求，你的系统越接近简单性和它的抽象：简单易懂的系统通常比复杂的系统都更容易修改。但是因为这是一个很重要的概念，我们会用另外一个词——可进化性，来代表数据系统的敏捷性。

## 小结

在本章中，我们探讨了思考数据系统的一些基本方法。这些原理将会在本书剩下的内容里面指引我们来探究更深的技术细节。

一个应用想要有用需要满足各种需求。有一些*功能需求*（它应该做什么，比如允许哪些数据需要用不同的方法来存储，获取，搜索和处理），和一些非功能需求（通用属性，例如安全性，可靠性，合规性，可扩展性，兼容性和可维护性）。在本章我们仔细讨论了可靠性，可扩展性和可维护性。

*可靠性*意味着让系统即使在有错误的情况下也能正常工作。故障可以是硬件故障（通常是随机的，互相没关联的），也可以是软件故障（通常是系统性bug，很难处理），也可以是人为故障（有人经常不经意间犯错误）。容错性技术可以让终端用户不受一些类型的故障的影响。

*可扩展性*意味着有即使在负载增加的时候也有保障高性能的策略。为了讨论可扩展性，我们首先徐璈一些描述负载和量化性能的方法。我们简要地用Twitter首页时间线做例子学习了描述用负载，和响应时间百分位点作为藐视性能的方式。在可扩展的系统中你可以在高负载的情况下增加处理容量来保持可靠性。

*可维护性*有很多方面，但是中药师是他让开发系统的工程团队和运维团队轻松很多。好的抽象可以帮助将降低复杂度，让系统更容易修改并能适应新的使用场景。好的运维意味着对系统健康程度有着好的洞察力，又搞笑的方式来管理系统。

很遗憾的，没有轻而易举的办法能把一个应用做到可靠的，可扩展的和扩维护的。但是，有一些模式和技术在各种各样的应用中反复出现。在接下来的几章中，我们会了解一些数据系统的实例并分析他们是如何朝着这些方向努力的。

在本书第三部分，我们会了解有不同组件协同工作的系统模式，比如图1-1里描述的那样。









